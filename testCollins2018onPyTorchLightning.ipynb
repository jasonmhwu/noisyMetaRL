{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/jit/_recursive.py:165: UserWarning: 'layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.\n",
      "  \" but it is a non-constant {}. Consider removing it.\".format(name, hint))\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "import pdb\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import Tuple, List\n",
    "from collections import OrderedDict\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import gym\n",
    "import networkx as nx\n",
    "import dgl\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pl_bolts.datamodules import ExperienceSourceDataset\n",
    "from pl_bolts.datamodules.experience_source import Experience\n",
    "\n",
    "from policies.pytorch_custom_lstm import LayerNormLSTMCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use CUDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create Environments</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
    "from stable_baselines3.common.cmd_util import make_vec_env\n",
    "\n",
    "from envs.Collins2018 import Collins2018Task\n",
    "\n",
    "num_envs = 5\n",
    "envs = make_vec_env(lambda: Collins2018Task(num_objects=(3, 4, 5, 6),\n",
    "                                            num_actions=6,\n",
    "                                            num_repeats=6,\n",
    "                                            max_observations=6,\n",
    "                                            mode='permutation'\n",
    "                                           ),\n",
    "                    n_envs=num_envs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Neural Network</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A2C_LSTM(pl.LightningModule):\n",
    "    \"\"\"Container Module with a LSTM layer leading to an action and value network module.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_inputs, num_outputs, num_LSTM):\n",
    "        super().__init__()\n",
    "        self.rnn = LayerNormLSTMCell(num_inputs, num_LSTM)\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(num_LSTM, num_outputs),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "        self.critic = nn.Linear(num_LSTM, 1)\n",
    "        \n",
    "        self.num_LSTM = num_LSTM\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_outputs = num_outputs\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        output, hidden = self.rnn(input, hidden)\n",
    "        value = self.critic(output)\n",
    "        action_log_prob = self.actor(output)\n",
    "        action_prob = Categorical(logits=action_log_prob)\n",
    "        return action_prob, value, hidden\n",
    "        \n",
    "    def init_weights(self):\n",
    "        init_scale = 1.4\n",
    "        self.rnn.layernorm_i.weight.data.uniform_(-init_scale, init_scale)\n",
    "        self.rnn.layernorm_i.bias.data.zero_()\n",
    "        self.rnn.layernorm_h.weight.data.uniform_(-init_scale, init_scale)\n",
    "        self.rnn.layernorm_h.bias.data.zero_()\n",
    "        self.rnn.layernorm_c.weight.data.uniform_(-init_scale, init_scale)\n",
    "        self.rnn.layernorm_c.bias.data.zero_()\n",
    "        self.actor[0].weight.data.uniform_(-init_scale, init_scale)\n",
    "        self.actor[0].bias.data.zero_()\n",
    "        self.critic.weight.data.uniform_(-init_scale, init_scale)\n",
    "        self.critic.bias.data.zero_()\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters())\n",
    "        return (\n",
    "            weight.new_zeros(batch_size, self.num_LSTM),\n",
    "            weight.new_zeros(batch_size, self.num_LSTM)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A2C_LSTM_System(pl.LightningModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        envs,\n",
    "        num_LSTM: int = 20,\n",
    "        lr: float = 7e-4,\n",
    "        gamma: float = 0.9,\n",
    "        value_loss_coef: float = 0.05,\n",
    "        entropy_coef: float = 0.05,\n",
    "        num_steps: int = 20,\n",
    "        num_batch_episodes: int = 1,\n",
    "        avg_reward_len: int = 5\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.envs = envs\n",
    "        self.num_envs, self.num_inputs = self.envs.reset().shape\n",
    "        self.num_outputs = envs.get_attr(\"num_actions\")[0]\n",
    "        self.num_LSTM = num_LSTM\n",
    "        self.net = A2C_LSTM(self.num_inputs, self.num_outputs, self.num_LSTM)\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.lr = lr\n",
    "        self.entropy_coef = entropy_coef\n",
    "        self.gamma = gamma\n",
    "        self.num_steps = num_steps\n",
    "        self.num_batch_episodes = num_batch_episodes\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Tracking metrics\n",
    "        self.total_steps = 0\n",
    "        self.total_rewards = [0]\n",
    "        self.done_episodes = 0\n",
    "        self.avg_rewards = 0\n",
    "        self.reward_sum = 0.0\n",
    "        self.batch_episodes = 0\n",
    "        self.avg_reward_len = avg_reward_len\n",
    "\n",
    "        self.batch_states = []\n",
    "        self.batch_hidden_states = []\n",
    "        self.batch_actions = []\n",
    "        self.batch_log_probs = []\n",
    "        self.batch_entropy = []\n",
    "        self.batch_values = []\n",
    "        self.batch_rewards = []\n",
    "        self.batch_masks = []\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.net.init_weights()\n",
    "       \n",
    "    def init_hidden(self, batch_size):\n",
    "        return self.net.init_hidden(batch_size)\n",
    "    \n",
    "    def reset_hidden(self, hidden):\n",
    "        for h in hidden:\n",
    "            h.detach()\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        return self.net(x, hidden)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #optimizer = self.optimizers(use_pl_optimizer=True)\n",
    "        #optimizer.zero_grad()\n",
    "        states, hidden_states, log_probs, values, returns, masks, entropy = batch\n",
    "\n",
    "        loss = self.loss(states, hidden_states, log_probs, entropy, values, returns)\n",
    "        print(log_probs)\n",
    "        print('at training step')\n",
    "        #self.manual_backward(loss, optimizer)\n",
    "        #pdb.set_trace()\n",
    "        print('finished BPTT')\n",
    "        #optimizer.step()\n",
    "        #pdb.set_trace()\n",
    "        log = {\n",
    "            \"episodes\": self.done_episodes,\n",
    "            \"reward\": self.total_rewards[-1],\n",
    "            \"avg_reward\": self.avg_rewards,\n",
    "        }\n",
    "\n",
    "        return OrderedDict({\n",
    "            \"loss\": loss,\n",
    "            \"avg_reward\": self.avg_rewards,\n",
    "            \"log\": log,\n",
    "            \"progress_bar\": log,\n",
    "        })\n",
    "        return loss\n",
    "\n",
    "    def train_batch(self) -> Tuple[List[torch.Tensor], List[torch.Tensor],\\\n",
    "                                   List[torch.Tensor], List[torch.Tensor],\\\n",
    "                                   List[torch.Tensor], List[torch.Tensor]]:\n",
    "    \n",
    "        state = torch.Tensor(self.envs.reset())\n",
    "        hidden = self.init_hidden(self.num_envs)\n",
    "        print('start of train_batch')\n",
    "\n",
    "        while True:\n",
    "            dist, value, next_hidden = self(state, hidden)\n",
    "            action = dist.sample()\n",
    "            next_state, reward, done, _ = self.envs.step(action.cpu().numpy())\n",
    "\n",
    "            self.batch_states.append(state)\n",
    "            #self.batch_hidden_states.append(hidden)\n",
    "            self.batch_hidden_states.append(0)\n",
    "            self.batch_rewards.append(reward)\n",
    "            self.batch_actions.append(action)\n",
    "            self.batch_log_probs.append(dist.log_prob(action))\n",
    "            self.batch_entropy.append(dist.entropy())\n",
    "            self.batch_values.append(value)\n",
    "            self.batch_masks.append(1-done)\n",
    "            state, hidden = torch.Tensor(next_state), next_hidden\n",
    "            self.total_steps += 1\n",
    "            \n",
    "            if any(done):\n",
    "                #self.batch_episodes += 1\n",
    "                #self.done_episodes += 1\n",
    "                #self.total_rewards.append(np.stack(self.batch_rewards).sum())\n",
    "                #self.avg_rewards = float(np.mean(self.total_rewards[-self.avg_reward_len:]))\n",
    "                \n",
    "            #if self.batch_episodes >= self.num_batch_episodes:  # right now only returns after each episode\n",
    "                returns = self.compute_returns(self.batch_rewards, self.batch_masks)\n",
    "                yield self.batch_states,\\\n",
    "                        self.batch_hidden_states,\\\n",
    "                        self.batch_log_probs,\\\n",
    "                        self.batch_values,\\\n",
    "                        returns,\\\n",
    "                        self.batch_masks,\\\n",
    "                        self.batch_entropy\n",
    "            \n",
    "                #self.batch_states.clear()\n",
    "                #self.batch_hidden_states.clear()\n",
    "                #self.batch_actions.clear()\n",
    "                #self.batch_log_probs.clear()\n",
    "                #self.batch_values.clear()\n",
    "                #self.batch_rewards.clear()\n",
    "                #self.batch_masks.clear()\n",
    "                self.batch_states = []\n",
    "                self.batch_hidden_states = []\n",
    "                self.batch_actions = []\n",
    "                self.batch_log_probs = []\n",
    "                self.batch_values = []\n",
    "                self.batch_rewards = []\n",
    "                self.batch_masks = []\n",
    "                \n",
    "                self.reset_hidden(hidden)\n",
    "                self.state = torch.Tensor(self.envs.reset())\n",
    "                \n",
    "\n",
    "    def loss(self, states, hidden_states, log_probs, entropy, values, returns) -> torch.Tensor:\n",
    "        log_probs = torch.cat(log_probs)\n",
    "        returns   = torch.cat(returns).detach()\n",
    "        values    = torch.cat(values).squeeze(-1)\n",
    "        entropy   = torch.cat(entropy).mean()\n",
    "\n",
    "        advantage   = returns - values\n",
    "        actor_loss  = -(log_probs * advantage.detach()).mean()\n",
    "        critic_loss = advantage.pow(2).mean()\n",
    "        #print(advantage)\n",
    "        #loss = actor_loss + 0.05 * critic_loss - 0.05 * entropy\n",
    "        loss = entropy\n",
    "        return loss\n",
    "\n",
    "    def compute_returns(self, rewards, masks):\n",
    "        R = 0\n",
    "        returns = []\n",
    "        for step in reversed(range(len(rewards))):\n",
    "            R = rewards[step] + self.gamma * R * masks[step]\n",
    "            returns.append(R)\n",
    "        return returns[::-1]\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.RMSprop(self.net.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "    \n",
    "    def _dataloader(self) -> DataLoader:\n",
    "        \"\"\"Initialize the Replay Buffer dataset used for retrieving experiences\"\"\"\n",
    "        dataset = ExperienceSourceDataset(self.train_batch)\n",
    "        dataloader = DataLoader(dataset=dataset, batch_size=1)\n",
    "        return dataloader\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Get train loader\"\"\"\n",
    "        return self._dataloader()\n",
    "    \n",
    "    def get_device(self, batch) -> str:\n",
    "        \"\"\"Retrieve device currently being used by minibatch\"\"\"\n",
    "        return batch[0][0][0].device.index if self.on_gpu else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name | Type     | Params\n",
      "----------------------------------\n",
      "0 | net  | A2C_LSTM | 2.3 K \n",
      "----------------------------------\n",
      "2.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 K     Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129f0ac8218e4825a54aa05e272dc69b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of train_batch\n",
      "[tensor([[-2.3496, -3.1155]], grad_fn=<StackBackward>), tensor([[-0.2780, -0.4852]], grad_fn=<StackBackward>), tensor([[-1.7767, -0.5954]], grad_fn=<StackBackward>), tensor([[-1.0231, -0.6375]], grad_fn=<StackBackward>), tensor([[-1.4080, -0.6947]], grad_fn=<StackBackward>), tensor([[-0.4312, -1.2437]], grad_fn=<StackBackward>), tensor([[-1.3595, -0.6275]], grad_fn=<StackBackward>), tensor([[-0.1967, -0.6817]], grad_fn=<StackBackward>), tensor([[-0.9402, -1.3000]], grad_fn=<StackBackward>), tensor([[-0.2668, -0.9838]], grad_fn=<StackBackward>), tensor([[-0.9476, -0.5001]], grad_fn=<StackBackward>), tensor([[-0.2791, -0.7827]], grad_fn=<StackBackward>), tensor([[-0.7784, -0.7788]], grad_fn=<StackBackward>), tensor([[-0.2712, -2.1448]], grad_fn=<StackBackward>), tensor([[-0.8161, -1.4934]], grad_fn=<StackBackward>), tensor([[-0.3288, -2.8070]], grad_fn=<StackBackward>), tensor([[-0.7635, -1.3512]], grad_fn=<StackBackward>), tensor([[-0.4458, -0.4841]], grad_fn=<StackBackward>)]\n",
      "at training step\n",
      "finished BPTT\n",
      "[tensor([[-0.5084, -1.9552]], grad_fn=<StackBackward>), tensor([[-1.1732, -0.6732]], grad_fn=<StackBackward>), tensor([[-0.4169, -0.5258]], grad_fn=<StackBackward>), tensor([[-1.9841, -0.7715]], grad_fn=<StackBackward>), tensor([[-0.8095, -1.1641]], grad_fn=<StackBackward>), tensor([[-0.7302, -1.0112]], grad_fn=<StackBackward>), tensor([[-1.3989, -1.8103]], grad_fn=<StackBackward>), tensor([[-0.8217, -0.6436]], grad_fn=<StackBackward>), tensor([[-1.3886, -0.8501]], grad_fn=<StackBackward>), tensor([[-1.3206, -0.7227]], grad_fn=<StackBackward>), tensor([[-1.1574, -0.8194]], grad_fn=<StackBackward>), tensor([[-0.6270, -0.9451]], grad_fn=<StackBackward>), tensor([[-0.3722, -1.0187]], grad_fn=<StackBackward>), tensor([[-1.1213, -0.9485]], grad_fn=<StackBackward>), tensor([[-0.3852, -0.6721]], grad_fn=<StackBackward>), tensor([[-0.8186, -0.8120]], grad_fn=<StackBackward>), tensor([[-0.4664, -0.8226]], grad_fn=<StackBackward>), tensor([[-0.9248, -3.1872]], grad_fn=<StackBackward>)]\n",
      "at training step\n",
      "finished BPTT\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [20, 3]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-54a15bf88250>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mseed_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_system\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_fit_start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_or_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtrain_or_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                     \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;31m# ------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;31m# when returning -1 from train_step, we end epoch early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                         \u001b[0;31m# optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mon_tpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tpu\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mTPU_AVAILABLE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0musing_native_amp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musing_native_amp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0musing_lbfgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_lbfgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         )\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m         \"\"\"\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m     def optimizer_zero_grad(\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, make_optimizer_step, *args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_optimizer_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;31m# make sure to call optimizer_closure when accumulating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36m__optimizer_step\u001b[0;34m(self, closure, profiler_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0maccelerator_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/optim/rmsprop.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain_step_and_backward_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    711\u001b[0m                                 \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                                 \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m                             )\n\u001b[1;32m    715\u001b[0m                             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step_and_backward\u001b[0;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[1;32m    814\u001b[0m                 \u001b[0;31m# backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_backward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0;31m# hook - call this hook only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, result, optimizer, opt_idx, *args, **kwargs)\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m             result.closure_loss = self.trainer.accelerator_backend.backward(\n\u001b[0;32m--> 843\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m             )\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, closure_loss, optimizer, opt_idx, *args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;31m# do backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# once backward has been applied, release graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, optimizer, optimizer_idx, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \"\"\"\n\u001b[1;32m   1161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_running_manual_backward\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoggle_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [20, 3]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "test_system = A2C_LSTM_System(envs)\n",
    "# save checkpoints based on avg_reward\n",
    "checkpoint_callback = ModelCheckpoint(save_top_k=1, monitor=\"avg_reward\", mode=\"max\", period=1, verbose=True)\n",
    "seed_everything(123)\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(test_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw a graph with N nodes\n",
    "def make_clique(num_nodes, draw_graph=False):\n",
    "    \"\"\"Create a Clique with num_nodes nodes.\"\"\"\n",
    "    u, v = [], []\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if i == j: continue\n",
    "            u.append(i)\n",
    "            v.append(j)\n",
    "\n",
    "    g = dgl.DGLGraph((u, v))\n",
    "    if draw_graph: nx.draw(g.to_networkx(), with_labels=True)\n",
    "    return g\n",
    "\n",
    "gg = make_clique(6, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRNLayer(nn.Module):\n",
    "    def __init__(self, g, num_inputs, num_hidden):\n",
    "        super().__init__()\n",
    "        self.w_i = nn.Linear(num_inputs, num_hidden, bias=False)\n",
    "        self.attn_i = nn.Linear(2*num_hidden, 1, bias=False)\n",
    "        self.w_h = nn.Linear(2*num_hidden, num_hidden, bias=False)\n",
    "        self.attn_h = nn.Linear(2*num_hidden, 1, bias=False)\n",
    "        \n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hidden = num_hidden\n",
    "        self.g = g\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reset learnable parameters.\"\"\"\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.w_i.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_i.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.w_h.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_h.weight, gain=gain)\n",
    "    \n",
    "    def edge_attention(self, edges):\n",
    "        z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=2)\n",
    "        a_h = self.attn_h(z2)\n",
    "        return {'e': F.leaky_relu(a_h)}\n",
    "    \n",
    "    def message_func(self, edges):\n",
    "        return {'z': edges.src['z'], 'e': edges.data['e']}\n",
    "    \n",
    "    def reduce_func(self, nodes):\n",
    "        a_h = F.softmax(nodes.mailbox['e'], dim=1)\n",
    "        h = torch.sum(a_h * nodes.mailbox['z'], dim=1)\n",
    "        return {'h': h}\n",
    "        \n",
    "    def forward(self, state, hidden):\n",
    "        pdb.set_trace()\n",
    "        \n",
    "        z_i = self.w_i(state)\n",
    "        a_i = F.softmax(torch.matmul(hidden, z_i.unsqueeze_(2)), dim=1)\n",
    "        # ger is deprecated outer product function, should be torch.outer in the future\n",
    "        h_i = torch.cat([torch.ger(a_i[b, :, 0], z_i[b, :, 0]).unsqueeze_(0) for b in range(hidden.size(0))], 0)\n",
    "        pdb.set_trace()\n",
    "        h_concat = torch.cat([hidden, h_i], dim=2)\n",
    "        \n",
    "        z = self.w_h(h_concat)\n",
    "        # a very basic model with no GNN \n",
    "        return z\n",
    "\n",
    "\n",
    "        #self.g.ndata['z'] = z.transpose_(0, 1)  # change to (num_nodes, batch_size)\n",
    "        #self.g.apply_edges(self.edge_attention)\n",
    "        #self.g.update_all(self.message_func, self.reduce_func)\n",
    "        #return self.g.ndata.pop('h').transpose_(0, 1)  # change to (batch_size, num_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadGRNLayer(nn.Module):\n",
    "    def __init__(self, g, num_inputs, num_hidden, num_heads, merge='cat'):\n",
    "        super().__init__()\n",
    "        self.g = g\n",
    "        self.heads = nn.ModuleList()\n",
    "        for i in range(num_heads):\n",
    "            self.heads.append(GRNLayer(g, num_inputs, num_hidden))\n",
    "        self.merge = merge\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "    def forward(self, state, hidden):\n",
    "        h_split = torch.split(hidden, num_hidden, dim=2)\n",
    "        head_outs = [attn_head(state, h) for attn_head, h in zip(self.heads, h_split)]\n",
    "        if self.merge == 'cat':\n",
    "            # concat on the output feature dimension (dim=1)\n",
    "            return torch.cat(head_outs, dim=2)\n",
    "        else:\n",
    "            # merge using average\n",
    "            return torch.mean(torch.stack(head_outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A2C_GRN(nn.Module):\n",
    "    def __init__(self, g, num_inputs, num_outputs, num_hidden, num_heads, num_iterations):\n",
    "        super().__init__()\n",
    "        self.g = g\n",
    "        self.layer = MultiHeadGRNLayer(g, num_inputs, num_hidden, num_heads)\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(num_hidden * num_heads * g.number_of_nodes(), num_outputs),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "        self.critic = nn.Linear(num_hidden * num_heads * g.number_of_nodes(), 1)\n",
    "        self.num_iterations = num_iterations\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_outputs = num_outputs\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "    def init_weights(self):\n",
    "        self.layer.reset_parameters()\n",
    "        init_scale = 1.4\n",
    "        self.actor[0].weight.data.uniform_(-init_scale, init_scale)\n",
    "        self.actor[0].bias.data.zero_()\n",
    "        self.critic.weight.data.uniform_(-init_scale, init_scale)\n",
    "        self.critic.bias.data.zero_()\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.randn(batch_size, self.g.number_of_nodes(), self.num_hidden * self.num_heads)\n",
    "        return nn.init.normal_(hidden)\n",
    "        \n",
    "    \n",
    "    def forward(self, state, hidden):\n",
    "        for it in range(self.num_iterations):\n",
    "            hidden = self.layer(state, hidden)\n",
    "        value = self.critic(torch.reshape(hidden, (hidden.size(0), -1)))\n",
    "        action_log_prob = self.actor(torch.reshape(hidden, (hidden.size(0), -1)))\n",
    "        action_prob = Categorical(logits=action_log_prob)\n",
    "        return action_prob, value, hidden\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing my code\n",
    "\n",
    "num_inputs = 3\n",
    "num_outputs = 3  # num_actions\n",
    "num_hidden = 5\n",
    "num_nodes = 7\n",
    "num_heads = 3\n",
    "num_iteration = 5\n",
    "state = torch.FloatTensor([1, 1, 1]).to(device)\n",
    "hidden = torch.randn(num_nodes, num_hidden * num_heads)\n",
    "\n",
    "g = make_clique(num_nodes)\n",
    "\n",
    "#model = GRNLayer(g, num_inputs, num_hidden)\n",
    "#hidden_out = model(state, hidden)\n",
    "#print(hidden_out.size())\n",
    "\n",
    "#model2 = MultiHeadGRNLayer(g, num_inputs, num_hidden, num_heads)\n",
    "#hidden_out2 = model2(state, hidden)\n",
    "#print(hidden_out2.size())\n",
    "\n",
    "#model3 = A2C_GRN(g, num_inputs, num_outputs, num_hidden, num_heads, num_iteration)\n",
    "#hidden = model3.init_hidden(2)\n",
    "#print(hidden.size())\n",
    "#prob, value, hi = model3(state, hidden)\n",
    "#print(prob)\n",
    "#print(value)\n",
    "#print(hi.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(vis=False):\n",
    "    state = envs.reset()\n",
    "    if vis: envs.render()\n",
    "    done = [False] * envs.num_envs\n",
    "    total_reward = 0\n",
    "    hidden = model.init_hidden(envs.num_envs)\n",
    "    \n",
    "    while not any(done):\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        dist, _, hidden = model(state, hidden)\n",
    "        \n",
    "        next_state, reward, done, _ = envs.step(dist.sample().cpu().numpy())\n",
    "        state = next_state\n",
    "        if vis: envs.render()\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>A2C: Synchronous Advantage Actor Critic</h1>\n",
    "<h3><a href=\"https://blog.openai.com/baselines-acktr-a2c/#a2canda3c\">OpenAI Blog:</a></h3>\n",
    "<p>The Asynchronous Advantage Actor Critic method (A3C) has been very influential since the paper was published. The algorithm combines a few key ideas:</p>\n",
    "\n",
    "<ul>\n",
    "    <li>An updating scheme that operates on fixed-length segments of experience (say, 20 timesteps) and uses these segments to compute estimators of the returns and advantage function.</li>\n",
    "    <li>Architectures that share layers between the policy and value function.</li>\n",
    "    <li>Asynchronous updates.</li>\n",
    "</ul>\n",
    "\n",
    "<p>After reading the paper, AI researchers wondered whether the asynchrony led to improved performance (e.g. â€œperhaps the added noise would provide some regularization or exploration?â€œ), or if it was just an implementation detail that allowed for faster training with a CPU-based implementation.</p>\n",
    "\n",
    "<p>As an alternative to the asynchronous implementation, researchers found you can write a synchronous, deterministic implementation that waits for each actor to finish its segment of experience before performing an update, averaging over all of the actors. One advantage of this method is that it can more effectively use of GPUs, which perform best with large batch sizes. This algorithm is naturally called A2C, short for advantage actor critic. (This term has been used in several papers.)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_returns(next_value, rewards, masks, gamma=0.99):\n",
    "    R = next_value\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        R = rewards[step] + gamma * R * masks[step]\n",
    "        returns.insert(0, R)\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs  = envs.observation_space.shape[0]\n",
    "num_outputs = envs.action_space.n\n",
    "\n",
    "#Hyper params:\n",
    "num_LSTM    = 20\n",
    "lr          = 7e-4\n",
    "num_steps   = 5\n",
    "batch_size  = 1\n",
    "\n",
    "model_LSTM = A2C_LSTM(num_inputs, num_outputs, num_LSTM).to(device)\n",
    "optimizer = optim.RMSprop(model_LSTM.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs  = envs.observation_space.shape[0]\n",
    "num_outputs = envs.action_space.n\n",
    "num_hidden = 40\n",
    "num_nodes = 6\n",
    "num_heads = 3\n",
    "num_iterations = 1\n",
    "lr = 7e-4\n",
    "num_steps = 5\n",
    "\n",
    "g = make_clique(num_nodes)\n",
    "model_GRN = A2C_GRN(g, num_inputs, num_outputs, num_hidden, num_heads, num_iterations).to(device)\n",
    "optimizer = optim.RMSprop(model_GRN.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames   = 20_000_000\n",
    "frame_idx    = 0\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-26-0ac0f61c65e2>(38)forward()\n",
      "-> z_i = self.w_i(state)\n",
      "(Pdb) c\n",
      "> <ipython-input-26-0ac0f61c65e2>(43)forward()\n",
      "-> h_concat = torch.cat([hidden, h_i], dim=2)\n",
      "(Pdb) h_i.shape\n",
      "torch.Size([5, 6, 40])\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b127ea385454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-355060739ac6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state, hidden)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0maction_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-e87de833c795>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state, hidden)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mh_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mhead_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mattn_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattn_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cat'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# concat on the output feature dimension (dim=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-e87de833c795>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mh_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mhead_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mattn_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattn_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cat'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# concat on the output feature dimension (dim=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-0ac0f61c65e2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state, hidden)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mh_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mh_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_concat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-0ac0f61c65e2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state, hidden)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mh_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mh_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_concat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t_record = time.time()\n",
    "model = model_GRN\n",
    "while frame_idx < max_frames:\n",
    "\n",
    "    log_probs = []\n",
    "    values    = []\n",
    "    rewards   = []\n",
    "    masks     = []\n",
    "    entropy = []\n",
    "    \n",
    "    done = [False] * num_envs\n",
    "    state = envs.reset()\n",
    "    hidden = model.init_hidden(num_envs)\n",
    "\n",
    "    while not any(done):\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        dist, value, hidden = model(state, hidden)\n",
    "        action = dist.sample()\n",
    "        next_state, reward, done, _ = envs.step(action.cpu().numpy())\n",
    "\n",
    "        log_prob = dist.log_prob(action).unsqueeze(1)\n",
    "        \n",
    "        entropy.append(dist.entropy().unsqueeze(1))\n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        masks.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "        \n",
    "        state = next_state\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if frame_idx % 10000 == 0:\n",
    "            test_reward = np.mean([test_env() for _ in range(3)])\n",
    "            test_rewards.append(test_reward)\n",
    "            print(f'at frame {int(frame_idx)},\\t mean testing reward {test_reward :.2f}')\n",
    "            \n",
    "        if frame_idx % 10000 == 0:\n",
    "            plot(frame_idx, test_rewards)\n",
    "            #print(f'at frame {int(frame_idx)},\\t takes time {(time.time() - t_record) :.2f} seconds')\n",
    "\n",
    "    returns = compute_returns(torch.zeros(envs.num_envs, 1), rewards, masks, gamma=0.9)\n",
    "    \n",
    "    log_probs = torch.cat(log_probs)\n",
    "    returns   = torch.cat(returns).detach()\n",
    "    values    = torch.cat(values)\n",
    "    entropy = torch.cat(entropy).mean()\n",
    "    \n",
    "    \n",
    "    advantage = returns - values\n",
    "    actor_loss  = -(log_probs * advantage.detach()).mean()\n",
    "    critic_loss = advantage.pow(2).mean()\n",
    "    loss = actor_loss + 0.05 * critic_loss - 0.05 * entropy\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.95 3.0963688\n"
     ]
    }
   ],
   "source": [
    "# LSTM: at 2M trials, testing reward is 10 +- 4.55\n",
    "# front end of GRN: at 3M trials, 8.1 +- 2.7\n",
    "# front end of GRN, task(3, 4, 5, 6): at 10M trials, 7.95 +- 3\n",
    "testing_rewards = [test_env() for _ in range(20)]\n",
    "print(np.mean(testing_rewards), np.std(testing_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_i = F.softmax(torch.matmul(hidden, z_i.unsqueeze_(2)), dim=1)\n",
    "        # ger is deprecated outer product function, should be torch.outer in the future\n",
    "        h_i = torch.cat([torch.ger(a_i[b, :, 0], z_i[b, :, 0]).unsqueeze_(0) for b in range(hidden.size(0))], 0)\n",
    "        h_concat = torch.cat([hidden, h_i], dim=2)\n",
    "        \n",
    "        z = self.w_h(h_concat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
